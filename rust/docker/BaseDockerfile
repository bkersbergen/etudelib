FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel AS builder

WORKDIR /usr/src/devel

RUN set -eux; \
    apt-get update; \
    apt-get upgrade -y; \
    apt-get install -y --no-install-recommends \
    libssl-dev \
    pkg-config \
    musl-tools \
    curl \
	llvm \
    clang \
    bc;

COPY ./src src
COPY ./Cargo.toml ./

RUN curl https://sh.rustup.rs -sSf | bash -s -- -y
ENV PATH="/root/.cargo/bin:${PATH}"

# Determine number of jobs based on the available memory (GB) and available CPU's to prevent OOM
RUN gb_per_job=8 && total_memory=$(free -b | awk '/Mem:/{print $2}') \
    && gb_jobs=$(echo "scale=0; (${total_memory} + 1024^3/2) / 1024^3/${gb_per_job}" | bc) \
    && ncpus=$(nproc) && jobs=$((gb_jobs<ncpus?gb_jobs:ncpus)) \
    && cargo build --release -j "${jobs}" --bin serving

RUN mkdir -p ./target/libtorch

RUN find ./ -type d -wholename "*out/libtorch/libtorch/lib" -exec cp -r {}/. ./target/libtorch \;

FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-devel AS runtime
RUN set -eux; \
    apt-get update; \
    apt-get upgrade -y;

WORKDIR /app

# Setup the local account
RUN groupadd -r app && useradd -r -g app -u 1002 app --home /app
RUN chown -R app:app /app
USER app

ENV LD_LIBRARY_PATH=/usr/local/lib/

COPY --chown=app:app --from=builder /usr/src/devel/target/release/serving /app
COPY --from=builder /usr/src/devel/target/release/libonnx* ${LD_LIBRARY_PATH}
COPY --from=builder /usr/src/devel/target/libtorch/* ${LD_LIBRARY_PATH}

ENTRYPOINT [ "/app/serving" , "./config/serving.yaml" ]
EXPOSE 7080/tcp
